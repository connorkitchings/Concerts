{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "from datetime import date, datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Show List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_show_dates(st_yr=1985, end_yr=2024):\n",
    "    base_url = 'http://everydaycompanion.com/'\n",
    "    tour_list = list(range(st_yr, end_yr + 1))\n",
    "    tour_list = [x for x in tour_list if x != 2004]  # :(\n",
    "    tour_df_list = pd.DataFrame()\n",
    "\n",
    "    # Function To Loop Setlist URLs\n",
    "    for yr in tour_list:\n",
    "            yr_str = str(yr)[-2:]\n",
    "            year_link = f\"{base_url}asp/tour{yr_str}.asp\"\n",
    "            response = requests.get(year_link)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            try:\n",
    "                tour_string = soup.find('p').get_text()\n",
    "            except:\n",
    "                print(f\"No data on Everyday Companion for {yr}.\")\n",
    "                break  \n",
    "            tour_string = re.sub(r'\\?\\?', '00', tour_string)\n",
    "\n",
    "            # Split the string into individual dates\n",
    "            venues = [venue.strip() for venue in re.split(r'\\d{2}/\\d{2}/\\d{2}', tour_string) if venue.strip()]\n",
    "            dates = re.findall(r'\\d{2}/\\d{2}/\\d{2}', tour_string)\n",
    "\n",
    "            tour_data = pd.DataFrame({\n",
    "                'date': dates,\n",
    "                'venue': venues\n",
    "            })\n",
    "\n",
    "            tour_data['link_date'] = tour_data['date'].apply(lambda x: str(x[6:])+str(x[0:2])+str(x[3:5]))\n",
    "            for index, value in tour_data['link_date'].items():\n",
    "                if value[0] in ['8', '9']:\n",
    "                    tour_data.at[index, 'link_date'] = '19' + value\n",
    "                if value[0] in ['0', '1', '2']:\n",
    "                    tour_data.at[index, 'link_date'] = '20' + value\n",
    "                    \n",
    "            tour_data['date_count'] = tour_data.groupby('link_date').cumcount() + 1\n",
    "            tour_data['assigned_letter'] = tour_data['date_count'].apply(lambda x: chr(ord('a') + x - 1))\n",
    "            tour_data['link'] = base_url+'setlists/'+tour_data['link_date']+tour_data['assigned_letter']+'.asp'\n",
    "            tour_data.drop(columns=['date_count','assigned_letter'], inplace=True)\n",
    "\n",
    "            tour_data['running_count'] = tour_data.groupby(['date', 'venue']).cumcount() + 1\n",
    "            \n",
    "            # Extract year, month, day from link\n",
    "            tour_data[['year', 'month', 'day']] = tour_data['link'].str.extract(r'(\\d{4})(\\d{2})(\\d{2})')\n",
    "            tour_data['date_ec'] = tour_data['date']\n",
    "            tour_data['date'] = pd.to_datetime(tour_data['date'], format='%m/%d/%y', errors='coerce').fillna(pd.NaT)\n",
    "            tour_data['weekday'] = pd.to_datetime(tour_data['date'], errors='coerce').dt.strftime('%A')\n",
    "\n",
    "            # Split venue information\n",
    "            tour_data[['venue_name', 'city', 'state']] = tour_data['venue'].str.rsplit(', ', n=2, expand=True)\n",
    "            tour_data['city'] = tour_data['city'].str.upper()\n",
    "            tour_data['venue_name'] = tour_data.apply(lambda row: row['venue_name'] if pd.notna(row['venue_name']) else ', '.join(row[:-2]), axis=1)\n",
    "            tour_data[['city', 'venue_name']] = tour_data[['city', 'venue_name']].apply(lambda col: col.str.upper())\n",
    "            tour_data.rename(columns={'venue':'venue_full', 'venue_name':'venue'},inplace=True)\n",
    "            tour_data['venue_full'] = tour_data['venue_full'].str.upper()\n",
    "\n",
    "            tour_data.drop(columns=['link_date', 'running_count'], inplace=True)\n",
    "            tour_data['show_index_withinyear'] = tour_data.index + 1\n",
    "            tour_df_list = pd.concat([tour_df_list, tour_data])\n",
    "            \n",
    "    # Combine DataFrames From Loop List\n",
    "    combined_tour_data = tour_df_list.reset_index(drop=True)\n",
    "    combined_tour_data['show_index_overall'] = combined_tour_data.index + 1\n",
    "\n",
    "    combined_tour_data['date_ec'] = combined_tour_data.apply(lambda row: f'??/{row[\"day\"]}/{row[\"year\"][-2:]}' if row['month'] == '00' else row['date_ec'],axis=1)\n",
    "    combined_tour_data['date_ec'] = combined_tour_data.apply(lambda row: f'{row[\"month\"]}/??/{row[\"year\"][-2:]}' if row['day'] == '00' else row['date_ec'],axis=1)\n",
    "    combined_tour_data['date_ec'] = combined_tour_data.apply(lambda row: f'??/??/{row[\"year\"][-2:]}' if ((row['month'] == '00')&(row['day'] == '00')) else row['date_ec'],axis=1)\n",
    "\n",
    "    combined_tour_data.sort_values(by=['show_index_overall','venue']).reset_index(drop=True, inplace=True)\n",
    "    mask = (combined_tour_data['venue'] != combined_tour_data['venue'].shift(1)) | (combined_tour_data['show_index_overall'] != combined_tour_data['show_index_overall'].shift(1) + 1)\n",
    "    combined_tour_data['run_index'] = mask.cumsum()\n",
    "\n",
    "    combined_tour_data = combined_tour_data[['date','year','month','day','weekday', 'date_ec','venue','city','state','show_index_overall', 'show_index_withinyear', 'run_index', 'venue_full','link']]\n",
    "    \n",
    "    venue_conditions = [\n",
    "    (combined_tour_data['venue'] == 'ADAMS CENTER') & (combined_tour_data['state'] == 'MT'),\n",
    "    (combined_tour_data['venue'] == 'AUDITORIUM THEATRE') & (combined_tour_data['city'] == 'CHICAGO'),\n",
    "    (combined_tour_data['venue'] == 'BAYFRONT ARENA') & (combined_tour_data['state'] == 'FL'),\n",
    "    (combined_tour_data['venue'] == \"FLEET PAVILION\") & (combined_tour_data['city'] == 'BOSTON'),\n",
    "    (combined_tour_data['venue'] == \"CAESAR'S TAHOE SHOWROOM\") & (combined_tour_data['state'] == 'NV')\n",
    "    ]\n",
    "\n",
    "    venue_replacements = [\n",
    "        'ADAMS FIELDHOUSE, UNIVERSITY OF MONTANA',\n",
    "        'AUDITORIUM THEATER, ROOSEVELT UNIVERSITY',\n",
    "        'BAYFRONT AUDITORIUM',\n",
    "        \"CAESAR'S TAHOE\",\n",
    "        \"CAESAR'S TAHOE\"\n",
    "        ]\n",
    "    \n",
    "    # Define conditions and corresponding replacements for city\n",
    "    city_conditions = [\n",
    "        (combined_tour_data['venue'] == '23 EAST CABARET') & (combined_tour_data['state'] == 'PA'),\n",
    "        (combined_tour_data['venue'] == \"CAESAR'S TAHOE\"),\n",
    "        (combined_tour_data['venue'] == 'CYNTHIA WOODS MITCHELL PAVILLION'),\n",
    "        (combined_tour_data['city'].isin(['N. LITTLE ROCK', 'NORTH LITTLE ROCK'])),\n",
    "        (combined_tour_data['city'] == 'MT. CRESTED BUTTE'),\n",
    "        (combined_tour_data['city'] == 'SNOWMASS VILLAGE'),\n",
    "        (combined_tour_data['city'] == 'ELON COLLEGE'),\n",
    "        (combined_tour_data['city'] == 'N. MYRTLE BEACH')\n",
    "        ]\n",
    "\n",
    "    city_replacements = [\n",
    "        'PHILADELPHIA',\n",
    "        'LAKE TAHOE',\n",
    "        'THE WOODLANDS',\n",
    "        'LITTLE ROCK',\n",
    "        'CRESTED BUTTE',\n",
    "        'SNOWMASS',\n",
    "        'ELON',\n",
    "        'MYRTLE BEACH'\n",
    "        ]\n",
    "    \n",
    "    # Use np.select to apply the conditions and replacements for venue and city\n",
    "    combined_tour_data['venue'] = np.select(venue_conditions, venue_replacements, default=combined_tour_data['venue'])\n",
    "    combined_tour_data['city'] = np.select(city_conditions, city_replacements, default=combined_tour_data['city'])\n",
    "\n",
    "    # Convert 'date' to datetime format (without immediately formatting back to string)\n",
    "    combined_tour_data['date'] = pd.to_datetime(combined_tour_data['date'], format='%m-%d-%y', errors='coerce')\n",
    "\n",
    "    # Get today's date\n",
    "    today = date.today()\n",
    "\n",
    "    # Find the first future date (including today)\n",
    "    future_dates = combined_tour_data[combined_tour_data['date'].dt.date >= today].dropna(subset=['date'])\n",
    "    first_future_date = future_dates['date'].min()\n",
    "\n",
    "    # Keep all past shows and only the first future show\n",
    "    if not pd.isna(first_future_date):\n",
    "        combined_tour_data = combined_tour_data[(combined_tour_data['date'] <= first_future_date)]\n",
    "\n",
    "    # Convert back to string format for display\n",
    "    combined_tour_data['date'] = combined_tour_data['date'].dt.strftime('%m/%d/%y')\n",
    "\n",
    "    return combined_tour_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Song Stats and Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_song_codes():\n",
    "    songcode_url = \"http://www.everydaycompanion.com/asp/songcode.asp\"\n",
    "    response = requests.get(songcode_url)\n",
    "    response.raise_for_status()  # Raise an exception for bad status codes\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    if tables:\n",
    "        tables_str = str(tables)  # Convert tables to string\n",
    "        tables_io = StringIO(tables_str)  # Wrap in StringIO\n",
    "        tables = pd.read_html(tables_io)\n",
    "    song_codes = tables[3].copy()\n",
    "\n",
    "    # Set the first row as header\n",
    "    song_codes.columns = song_codes.iloc[0]  # Assign first row as header\n",
    "    song_codes = song_codes[1:].reset_index(drop=True)  # Drop the first row and reset\n",
    "\n",
    "    song_codes = song_codes.rename(columns={'Code':'code','Title':'song', 'First': 'ftp', 'Last': 'ltp', 'Times Played': 'times_played', 'Also Known As': 'aka'})\n",
    "    column = song_codes.pop('song')\n",
    "    song_codes.insert(0, 'song', column)\n",
    "\n",
    "    song_codes = song_codes.astype({\n",
    "        'song': str,\n",
    "        'code': str,\n",
    "        'times_played': int\n",
    "    })\n",
    "    song_codes['aka'] = song_codes['aka'].fillna('').astype(str)\n",
    "    # Convert 'ftp' and 'ltp' to datetime and format as mm/dd/yyyy\n",
    "    song_codes['ftp'] = pd.to_datetime(song_codes['ftp'], format='%m/%d/%y', errors='coerce').dt.strftime('%m/%d/%y')\n",
    "    song_codes['ltp'] = pd.to_datetime(song_codes['ltp'], format='%m/%d/%y', errors='coerce').dt.strftime('%m/%d/%y')\n",
    "    return song_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Setlist Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "comma_songs = list(['Guns', 'And Money', 'Let Me Follow You Down', 'Let Me Hold Your Hand', \"Please Don't Go\", 'Rattle', 'And Roll', 'Narrow Mind', 'Woman Smarter'])\n",
    "comma_songs_completer = {'Lawyers': 'Lawyers Guns And Money', 'Baby': 'One of the 3 Baby Songs', 'Shake':'Shake, Rattle, And Roll', 'Weak Brain':'Weak Brain, Narrow Mind', \\\n",
    "                         'Man Smart':'Man Smart, Woman Smarter'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_setlist_from_link(x):\n",
    "    setlist_link = x\n",
    "    response = requests.get(setlist_link)\n",
    "    response.raise_for_status()  # Raise an exception for bad status codes\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    if tables:\n",
    "        tables_str = str(tables)  # Convert tables to string\n",
    "        tables_io = StringIO(tables_str)  # Wrap in StringIO\n",
    "        tables = pd.read_html(tables_io)\n",
    "    setlist_raw = tables[4].copy()\n",
    "    setlist_raw['Raw'] = setlist_raw[0].str.replace(\"ï\", \"i\")\n",
    "    setlist_raw['set'] = setlist_raw['Raw'].apply(lambda x: x[:3] if x[:2] in (['0:', '1:', '2:', '3:', '4:', 'E:','E1','E2','E3','E4']) else 'Notes')\n",
    "    setlist_raw['set'] = setlist_raw['set'].apply(lambda x: 'Details' if x[:2] == '??'or re.match(r\"^\\d{2}/\", x[:2]) else x)\n",
    "    setlist_raw['set'] = setlist_raw['set'].str.strip()\n",
    "    setlist_raw['Raw'] = setlist_raw['Raw'].str.lstrip()\n",
    "    setlist_raw['Raw'] = np.where(setlist_raw['set'].isin(['0', '1', '2', '3', '4', 'E']), setlist_raw['Raw'].str.replace(\"^.{3}\", \"\", regex=True), setlist_raw['Raw'])\n",
    "\n",
    "    songs1 = setlist_raw[~setlist_raw['set'].isin(['Details', 'Notes'])].copy()\n",
    "    songs1['Raw'] = songs1['Raw'].str.replace('>', ',>', regex=False)\n",
    "    songs1['Raw'] = songs1['Raw'].str.split(',')\n",
    "    songs2 = songs1.explode('Raw').copy()\n",
    "    songs2['into'] = songs2['Raw'].apply(lambda x: 1 if '>' in x else 0)\n",
    "    songs2['Raw'] = songs2['Raw'].str.replace('>', '', regex=False)\n",
    "    songs2['Raw'] = songs2['Raw'].str.lstrip()\n",
    "    songs2['Raw'] = songs2['Raw'].replace('|'.join(songs2['set']), '', regex=True)\n",
    "    songs3 = songs2[~songs2['Raw'].str.contains('|'.join(comma_songs))].copy()\n",
    "    songs3['Raw'] = songs3['Raw'].map(comma_songs_completer).fillna(songs3['Raw'])\n",
    "    songs3['song_name'] = songs3['Raw'].str.upper().str.strip()\n",
    "    songs3['notes_id'] = songs3['song_name'].str.count(r\"\\*\")\n",
    "    songs3['song_notes_key'] = np.where(songs3['notes_id'] == 0, \"\", songs3['notes_id'].apply(lambda x: '*' * x))\n",
    "    songs4 = songs3.reset_index(drop=True).copy()\n",
    "    songs4['song_index_show'] = songs4.index + 1\n",
    "    songs4['song_index_set'] = songs4.groupby('set').cumcount() + 1\n",
    "    songs = songs4[['set','song_name','into','song_index_show','song_index_set','song_notes_key','notes_id']].copy()\n",
    "    songs['link'] = str(setlist_link)\n",
    "\n",
    "    songs['song_name'] = songs['song_name'].str.upper().str.replace('*', '')\n",
    "    conditions = [songs['song_name'].isin(['???', 'ARU/WSP JAM']),songs['song_name'] == 'THIS MUST BE THE PLACE (NA<EF>VE MELODY)',songs['song_name'] == 'W<CR>M']\n",
    "    replacements = ['JAM','THIS MUST BE THE PLACE (NAIEVE MELODY)','WURM']\n",
    "    songs['song_name'] = np.select(conditions, replacements, default=songs['song_name'])\n",
    "\n",
    "    songs = songs[['song_name', 'set','song_index_set','song_index_show','into','song_notes_key',\\\n",
    "                    'notes_id', 'link']]\n",
    "\n",
    "    is_notes = songs['notes_id'].sum()\n",
    "    if is_notes > 0:\n",
    "        try:\n",
    "            notes_df = setlist_raw.loc[setlist_raw['set'].isin(['Notes'])].loc[:, ['Raw']]\n",
    "            notes_str_series = notes_df['Raw'].iloc[1]\n",
    "            notes_split = re.split(r'(\\*+|\\[)', notes_str_series)\n",
    "            notes_split = [s for s in notes_split if s]\n",
    "            notes_split = [s for s in notes_split if s.startswith(' ') or s.startswith('*')]\n",
    "            notes_df = pd.DataFrame({'song_notes_key': notes_split[::2], 'song_note_detail': notes_split[1::2]})\n",
    "            if setlist_link==\"http://everydaycompanion.com/setlists/20091017a.asp\":\n",
    "                notes_df = pd.DataFrame({'song_notes_key':['*'], 'song_note_detail':['with The Allman Brothers']})\n",
    "            if setlist_link==\"http://everydaycompanion.com/setlists/20161030a.asp\":\n",
    "                notes_df = pd.DataFrame({'song_notes_key':['*'], 'song_note_detail':['Steve Lopez on Percussion']})\n",
    "                notes_df['song_note_detail'] = notes_df['song_note_detail'].str.lstrip()\n",
    "            songs_final = pd.merge(songs, notes_df, how='left', left_on='song_notes_key', right_on='song_notes_key')\n",
    "            songs_final.drop(columns=['song_notes_key', 'notes_id'], inplace=True)\n",
    "        except AttributeError as notes_error:\n",
    "            songs_final = songs.copy()\n",
    "            songs_final['song_note_detail'] = ''\n",
    "    else:\n",
    "        songs_final = songs.copy()\n",
    "        songs_final = songs_final.assign(song_note_detail='')\n",
    "    songs_final = songs_final.reset_index(drop=True)\n",
    "    return songs_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_setlists(link_list, method='all'):\n",
    "    if method=='all':\n",
    "        all_setlists = pd.DataFrame()\n",
    "        for link in link_list:\n",
    "            link_setlist = get_setlist_from_link(link)\n",
    "            all_setlists = pd.concat([all_setlists, link_setlist]).reset_index(drop=True)\n",
    "    if method=='update':\n",
    "        current_year = str(datetime.now().year)\n",
    "        previous_year = str(datetime.now().year - 1)\n",
    "        try:\n",
    "            script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        except NameError:\n",
    "            script_dir = os.getcwd()\n",
    "        base_dir = os.path.dirname(script_dir)\n",
    "        data_path = os.path.join(base_dir, \"Data\", \"Widespread_Panic\")\n",
    "        all_setlists = pd.read_csv(os.path.join(data_path, \"setlistdata.csv\"))\n",
    "        filtered_link_list = [link for link in link_list if current_year in link.split('/')[-1] or previous_year in link.split('/')[-1]]\n",
    "        for link in filtered_link_list:\n",
    "            link_setlist = get_setlist_from_link(link)\n",
    "            all_setlists = pd.concat([all_setlists, link_setlist]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    return all_setlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data on Everyday Companion for 2025.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>date_ec</th>\n",
       "      <th>venue</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>show_index_overall</th>\n",
       "      <th>show_index_withinyear</th>\n",
       "      <th>run_index</th>\n",
       "      <th>venue_full</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1985</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>??/??/85</td>\n",
       "      <td>A-FRAME, WEYMANDA COURT</td>\n",
       "      <td>ATHENS</td>\n",
       "      <td>GA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A-FRAME, WEYMANDA COURT, ATHENS, GA</td>\n",
       "      <td>http://everydaycompanion.com/setlists/19850000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/24/85</td>\n",
       "      <td>1985</td>\n",
       "      <td>02</td>\n",
       "      <td>24</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>02/24/85</td>\n",
       "      <td>A-FRAME, WEYMANDA COURT</td>\n",
       "      <td>ATHENS</td>\n",
       "      <td>GA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A-FRAME, WEYMANDA COURT, ATHENS, GA</td>\n",
       "      <td>http://everydaycompanion.com/setlists/19850224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06/22/85</td>\n",
       "      <td>1985</td>\n",
       "      <td>06</td>\n",
       "      <td>22</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>06/22/85</td>\n",
       "      <td>UPTOWN LOUNGE</td>\n",
       "      <td>ATHENS</td>\n",
       "      <td>GA</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>UPTOWN LOUNGE, ATHENS, GA</td>\n",
       "      <td>http://everydaycompanion.com/setlists/19850622...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/19/85</td>\n",
       "      <td>1985</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>10/19/85</td>\n",
       "      <td>US AWARE FESTIVAL</td>\n",
       "      <td>ATHENS</td>\n",
       "      <td>GA</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>US AWARE FESTIVAL, ATHENS, GA</td>\n",
       "      <td>http://everydaycompanion.com/setlists/19851019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/24/85</td>\n",
       "      <td>1985</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>10/24/85</td>\n",
       "      <td>PHI DELTA THETA HOUSE, UNIVERSITY OF GEORGIA</td>\n",
       "      <td>ATHENS</td>\n",
       "      <td>GA</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>PHI DELTA THETA HOUSE, UNIVERSITY OF GEORGIA, ...</td>\n",
       "      <td>http://everydaycompanion.com/setlists/19851024...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  year month day   weekday   date_ec  \\\n",
       "0       NaN  1985    00  00       NaN  ??/??/85   \n",
       "1  02/24/85  1985    02  24    Sunday  02/24/85   \n",
       "2  06/22/85  1985    06  22  Saturday  06/22/85   \n",
       "3  10/19/85  1985    10  19  Saturday  10/19/85   \n",
       "4  10/24/85  1985    10  24  Thursday  10/24/85   \n",
       "\n",
       "                                          venue    city state  \\\n",
       "0                       A-FRAME, WEYMANDA COURT  ATHENS    GA   \n",
       "1                       A-FRAME, WEYMANDA COURT  ATHENS    GA   \n",
       "2                                 UPTOWN LOUNGE  ATHENS    GA   \n",
       "3                             US AWARE FESTIVAL  ATHENS    GA   \n",
       "4  PHI DELTA THETA HOUSE, UNIVERSITY OF GEORGIA  ATHENS    GA   \n",
       "\n",
       "   show_index_overall  show_index_withinyear  run_index  \\\n",
       "0                   1                      1          1   \n",
       "1                   2                      2          1   \n",
       "2                   3                      3          2   \n",
       "3                   4                      4          3   \n",
       "4                   5                      5          4   \n",
       "\n",
       "                                          venue_full  \\\n",
       "0                A-FRAME, WEYMANDA COURT, ATHENS, GA   \n",
       "1                A-FRAME, WEYMANDA COURT, ATHENS, GA   \n",
       "2                          UPTOWN LOUNGE, ATHENS, GA   \n",
       "3                      US AWARE FESTIVAL, ATHENS, GA   \n",
       "4  PHI DELTA THETA HOUSE, UNIVERSITY OF GEORGIA, ...   \n",
       "\n",
       "                                                link  \n",
       "0  http://everydaycompanion.com/setlists/19850000...  \n",
       "1  http://everydaycompanion.com/setlists/19850224...  \n",
       "2  http://everydaycompanion.com/setlists/19850622...  \n",
       "3  http://everydaycompanion.com/setlists/19851019...  \n",
       "4  http://everydaycompanion.com/setlists/19851024...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_list = load_show_dates(1985, int(date.today().year))\n",
    "show_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>code</th>\n",
       "      <th>ftp</th>\n",
       "      <th>ltp</th>\n",
       "      <th>times_played</th>\n",
       "      <th>aka</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>???</td>\n",
       "      <td>???</td>\n",
       "      <td>06/06/87</td>\n",
       "      <td>04/23/93</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One Kind Favor</td>\n",
       "      <td>1FAVOR</td>\n",
       "      <td>07/18/97</td>\n",
       "      <td>07/24/22</td>\n",
       "      <td>54</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Arm Steve</td>\n",
       "      <td>1STEVE</td>\n",
       "      <td>04/18/98</td>\n",
       "      <td>06/21/24</td>\n",
       "      <td>309</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Second Skin</td>\n",
       "      <td>2NDSKN</td>\n",
       "      <td>03/24/05</td>\n",
       "      <td>04/15/24</td>\n",
       "      <td>165</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tonight's the Night</td>\n",
       "      <td>2NNGHT</td>\n",
       "      <td>05/14/03</td>\n",
       "      <td>04/26/05</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                 song    code       ftp       ltp  times_played aka\n",
       "0                  ???     ???  06/06/87  04/23/93             3    \n",
       "1       One Kind Favor  1FAVOR  07/18/97  07/24/22            54    \n",
       "2        One Arm Steve  1STEVE  04/18/98  06/21/24           309    \n",
       "3          Second Skin  2NDSKN  03/24/05  04/15/24           165    \n",
       "4  Tonight's the Night  2NNGHT  05/14/03  04/26/05             9    "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_data = load_song_codes()\n",
    "song_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025\n",
      "['http://everydaycompanion.com/setlists/20240118a.asp', 'http://everydaycompanion.com/setlists/20240119a.asp', 'http://everydaycompanion.com/setlists/20240120a.asp', 'http://everydaycompanion.com/setlists/20240322a.asp', 'http://everydaycompanion.com/setlists/20240323a.asp', 'http://everydaycompanion.com/setlists/20240324a.asp', 'http://everydaycompanion.com/setlists/20240414a.asp', 'http://everydaycompanion.com/setlists/20240415a.asp', 'http://everydaycompanion.com/setlists/20240416a.asp', 'http://everydaycompanion.com/setlists/20240417a.asp', 'http://everydaycompanion.com/setlists/20240425a.asp', 'http://everydaycompanion.com/setlists/20240524a.asp', 'http://everydaycompanion.com/setlists/20240525a.asp', 'http://everydaycompanion.com/setlists/20240620a.asp', 'http://everydaycompanion.com/setlists/20240621a.asp', 'http://everydaycompanion.com/setlists/20240622a.asp', 'http://everydaycompanion.com/setlists/20240623a.asp']\n",
      "Execution time: 0:00:05.317541\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>set</th>\n",
       "      <th>song_index_set</th>\n",
       "      <th>song_index_show</th>\n",
       "      <th>into</th>\n",
       "      <th>song_notes_key</th>\n",
       "      <th>notes_id</th>\n",
       "      <th>link</th>\n",
       "      <th>song_note_detail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62115</th>\n",
       "      <td>BLUE INDIAN</td>\n",
       "      <td>2:</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://everydaycompanion.com/setlists/20240623...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62116</th>\n",
       "      <td>LAWYERS GUNS AND MONEY</td>\n",
       "      <td>2:</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://everydaycompanion.com/setlists/20240623...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62117</th>\n",
       "      <td>LIFE AS A TREE</td>\n",
       "      <td>E:</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://everydaycompanion.com/setlists/20240623...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62118</th>\n",
       "      <td>PIGEONS</td>\n",
       "      <td>E:</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://everydaycompanion.com/setlists/20240623...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62119</th>\n",
       "      <td>POSTCARD</td>\n",
       "      <td>E:</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://everydaycompanion.com/setlists/20240623...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    song_name set  song_index_set  song_index_show  into  \\\n",
       "62115             BLUE INDIAN  2:              10               20     1   \n",
       "62116  LAWYERS GUNS AND MONEY  2:              11               21     0   \n",
       "62117          LIFE AS A TREE  E:               1               22     0   \n",
       "62118                 PIGEONS  E:               2               23     0   \n",
       "62119                POSTCARD  E:               3               24     0   \n",
       "\n",
       "      song_notes_key  notes_id  \\\n",
       "62115                      0.0   \n",
       "62116                      0.0   \n",
       "62117                      0.0   \n",
       "62118                      0.0   \n",
       "62119                      0.0   \n",
       "\n",
       "                                                    link song_note_detail  \n",
       "62115  http://everydaycompanion.com/setlists/20240623...                   \n",
       "62116  http://everydaycompanion.com/setlists/20240623...                   \n",
       "62117  http://everydaycompanion.com/setlists/20240623...                   \n",
       "62118  http://everydaycompanion.com/setlists/20240623...                   \n",
       "62119  http://everydaycompanion.com/setlists/20240623...                   "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "link_list = show_list.link.unique()\n",
    "link_list = [s.lower() for s in link_list]\n",
    "all_setlists = load_setlists(link_list, method='update')\n",
    "end_time = datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Execution time:', elapsed_time)\n",
    "all_setlists.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    script_dir = os.getcwd()\n",
    "base_dir = os.path.dirname(script_dir)\n",
    "save_path = os.path.join(base_dir, \"Data\", \"Widespread_Panic\")\n",
    "\n",
    "show_list.to_csv(os.path.join(save_path, \"showdata.csv\"), index=False)\n",
    "song_data.to_csv(os.path.join(save_path, \"songdata.csv\"), index=False)\n",
    "all_setlists.to_csv(os.path.join(save_path, \"setlistdata.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
